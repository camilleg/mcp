// Pseudocode spec for the sound input class.
// Paris is working on the feature object.

// Blocking interface instead of cumbersome callbacks for now.
// When reading, use the stream parameters to resample and channel-remap on the fly.

// Constructors

input_t( foo stream, bool in_or_out, int ch, double sr, enum frm)
{
  switch( stream){
  case "file"
  use ffmpeg
  case "socket"
  use homebrew code?
  case "url"
  use VLC?
  case "adc"
  Use portaudio
  case "dac"
  Use portaudio
  }
}

// Seeking

seek( long s); // move to sample frame s
seek( double t); // move to second t

// Writing

write( array<T> &x, long offset, int channel_mask); // sample frames
write( array<T> &x, double offset, int channel_mask); // seconds

write_add( array<T> &x, long offset, int channel_mask); // sample frames
write_add( array<T> &x, double offset, int channel_mask); // seconds

// Mark's written and tested Segment and Tree, still need to write Rule.
// A chart parser that builds upward from abstract Class Segment
//   { int startTime, int endTime, float logLikelihood, int index of nonterminal/senone/word index }.
// Mark refactors class Segment to read Camille's representation for AV feature vectors.
// Mark's code could do:
vector<map<int,Segment>> chartByStime, chartByEtime;
Tree<SegmentByLl> bestfirst;
GMM gmm[N];
Rule rule [R];
while(in){
  t=in.time ();
  x=in.read ();
  y=feature (x);
  for(n=0;n<N;n++) {
    ll=gmm[n].ll(y);
    Segment s= Segment (t-1,t,ll,n);
    bestfirst.insert (&((SegmentByLl)s));
    chartByStime(t-1)(n)=s;
    chartByEtime(t)(n)=s;
    beam =bestfirst.first ().value() - beamwidth;
    while ((b=bestfirst.firstpop()).value () > beam) {
     Check to see if any rules can fire on b, if so then add them to bestfirst and the charts.
    }
  }
}
